{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from haversine import haversine as hvs, Unit\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "import math\n",
    "from datetime import datetime, timedelta"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Procesar samples_with_nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples_with_nan = pd.read_csv('samples_with_nan.csv', index_col=None)\n",
    "# len(samples_with_nan['init_stop'].unique())   #83 paraderos  # 2560 samples con nan\n",
    "#samples_with_nan['id_sample'] = samples_with_nan.apply(lambda row: int(row.name)//82) \n",
    "#samples_with_nan.apply(lambda row: int(row.name))#(//82) \n",
    "samples_with_nan['id_sample'] = samples_with_nan.index.map(lambda row: int(row)//83)\n",
    "columna = samples_with_nan.pop('id_sample') # Extraemos la columna C y la guardamos en una variable\n",
    "samples_with_nan.insert(0, 'id_sample', columna) # Insertamos la columna C en la posiciÃ³n 1\n",
    "#samples_with_nan.to_csv('samples_with_nan.csv')\n",
    "samples_with_nan.to_csv('samples_with_nan.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#EJECUTAR CUANDO EXISTA LA COLUMNA UNNAMED 0\n",
    "samples_with_nan = pd.read_csv('samples_with_nan.csv', index_col=None)\n",
    "samples_with_nan.drop(columns=['Unnamed: 0'], inplace=True)\n",
    "samples_with_nan.to_csv('samples_with_nan.csv', index=False)\n",
    "samples_with_nan"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filtro de time_travel para moestrar todos los menores a 12 segundos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples_with_nan = pd.read_csv('samples_with_nan.csv', index_col=None)\n",
    "#samples_with_nan.nlargest(50,columns='time_travel')\n",
    "#samples_with_nan[samples_with_nan['time_travel']>=960]['id_sample'].unique #960 segundos equivale a 10 minutos\n",
    "samples_with_nan[samples_with_nan['time_travel']<12]['id_sample'].unique().shape #960 segundos equivale a 10 minutos"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Porcentaje de nan en time_travel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples_with_nan = pd.read_csv('samples_with_nan.csv', index_col=None)\n",
    "#samples_with_nan.nsmallest(50,columns='time_travel')\n",
    "samples_with_nan['time_travel'].isna().sum()/samples_with_nan['time_travel'].shape[0]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filtrar por fecha "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples_with_nan = pd.read_csv('samples_with_nan.csv', index_col=None)\n",
    "samples_with_nan['date_time_init'] = pd.to_datetime(samples_with_nan['date_time_init'])\n",
    "samples_with_nan['date_time_end'] = pd.to_datetime(samples_with_nan['date_time_end'])\n",
    "\n",
    "fecha_filtro = pd.to_datetime('2023-03-12').date()\n",
    "df_filtrado = samples_with_nan[samples_with_nan['date_time_init'].dt.date == fecha_filtro]\n",
    "df_filtrado.nsmallest(20, ['time_travel'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calcular el promedio\n",
    "means = []\n",
    "for col in df_sp.columns:\n",
    "    means.append(round(df_sp[col].mean(), 0))\n",
    "\n",
    "print(means)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gg = pd.read_csv('samples.csv')\n",
    "gg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def curar(row, df):\n",
    "    print(row.name)\n",
    "    if math.isnan(row['time_travel']):\n",
    "        row['time_travel'] = means[row.name]\n",
    "        if row.name == 0:\n",
    "            row['date_time_end'] =  df.loc[row.name + 1, 'date_time_init']\n",
    "            row['date_time_init'] = row['date_time_end'] - datetime.timedelta(seconds= row['time_travel'])\n",
    "        else:\n",
    "            row['date_time_init'] =  df.loc[row.name - 1, 'date_time_end']\n",
    "            row['date_time_end'] =  row['date_time_init'] + datetime.timedelta(seconds= row['time_travel'])\n",
    "    return row\n",
    "    \n",
    "\n",
    "for i, row in gg.iterrows():\n",
    "        if math.isnan(row['time_travel']):\n",
    "            travel_t = means[row.name]\n",
    "            if row.name == 0:\n",
    "                datetime_end =  gg.loc[i + 1, 'date_time_init']\n",
    "                datetime_init = datetime_end - datetime.timedelta(seconds=travel_t)\n",
    "            else:\n",
    "                datetime_init =  df_af.loc[i - 1, 'date_time_end']\n",
    "                datetime_end =  datetime_init + datetime.timedelta(seconds=travel_t)\n",
    "            df_af.loc[df_af.shape[0]] = [row['init_stop'], row['end_stop'], row['linkref'],datetime_init, datetime_end, travel_t, np.nan, np.nan]\n",
    "        else:\n",
    "            df_af.loc[df_af.shape[0]] = list(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list_samples[85]\n",
    "df_tmp = pd.concat(list_samples)\n",
    "df_tmp.to_csv('samples.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
